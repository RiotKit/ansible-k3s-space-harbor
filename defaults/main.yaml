# =====================
#  Main settings
# =====================

k3s_version: "v1.23.6+k3s1"       # https://github.com/k3s-io/k3s/releases
argocd_version: "v2.3.2"          # https://github.com/argoproj/argo-cd/releases
secrets_version: "2.1.7"          # https://artifacthub.io/packages/helm/bitnami-labs/sealed-secrets
telegraf_chart_version: "1.8.17"  # https://artifacthub.io/packages/helm/influxdata/telegraf
traefik_chart_version: "10.19.0"  # https://artifacthub.io/packages/helm/traefik/traefik

# ============================
#  Tools installed on machine
# ============================
tool_helm_version: "v3.8.1"       # https://github.com/helm/helm/releases
tool_kubeseal_version: "0.17.5"  # https://github.com/bitnami-labs/sealed-secrets/releases (notice: only versions with released asset "kubeseal-linux-amd64")

main_domain: "example.org"   # main public DNS domain of your cluster. All services will be exposed as subdomains under this domain
timezone: "Europe/Warsaw"
force_k3s_upgrade: false     # set this from CLI "-e force_k3s_upgrade=true" to upgrade the cluster with Ansible
vpn_enabled: true            # communicate between cluster nodes over VPN, K3S will use {{ flannel_iface }} as main interface when vpn_enabled=true
flannel_iface: wg0           # set this per node if you have multiple VPN interfaces
canal_enabled: true

# =========
# Firewall
# =========
firewall_enabled: true       # install and configure UFW firewall
firewall_interface: eth0
firewall_inventory_hosts_group_name: cluster   # a name of a group in Ansible inventory from which take the list of hosts
firewall_ports_internal:
    # etcd
    - port: 10250
      proto: tcp
    # Node Exporter (Prometheus/Victoria metrics)
    - port: 9100
      proto: tcp
    # exposed NodePorts
    - port: "30000:32767"
      proto: tcp
    - port: "30000:32767"
      proto: udp
    # API Server
    - port: 6443
      proto: tcp
    # Ingress NGINX
    - port: 8082
      proto: tcp
firewall_ports_public:
    - port: 80
      proto: tcp
    - port: 443
      proto: tcp
    - port: 22
      proto: tcp
    # VPN
    - port: 51820
      proto: udp
    - port: 51821
      proto: udp
    - port: 443
      proto: udp

# configure, if you have multiple clusters and access them by same network/VPN
net_cluster_cidr: "10.42.0.0/16"
net_services_cidr: "10.43.0.0/16"
cluster_data_path: "/var/lib/rancher/k3s"
cluster_api_bind_address: "0.0.0.0"
cluster_api_restrict_access:  # todo restrict access on iptables/ufw
    - "{{ net_cluster_cidr }}"
    - "{{ vpn_cidr }}"
    - "{{ net_services_cidr }}"
administrative_services_restrict_access: # restrict access by subnet/ip to ArgoCD and other administrative services
    - "{{ net_cluster_cidr }}"
    - "{{ vpn_cidr }}"
    - "{{ net_services_cidr }}"
node_labels: []
    # - arch=arm
node_taints: ""
primary_api_allowed_ips:
    - "{{ vpn_cidr }}"
kubelet_args: []
# - "--eviction-hard=memory.available<350Mi,nodefs.available<20Gi"
k3s_datastore_endpoint: sqlite
vpn_flannel_backend: wireguard

# set it to true for better multi-node cluster stability
# additionally a good practice is to keep your pods to have defined requests and limits
noschedule_on_primary: false

# =====================
#  GIT repository for a Cluster is a SINGLE SOURCE OF TRUTH
# =====================
cluster_git_repository:
    remote: "git://github.com/smthing"
    branch: "main"
    argocd_read_only_access_key: ""
    deployment_time_access_key: ""  # access key with permissions to write to repository (private ssh-rsa)

# ========
#  ArgoCD
# ========
argocd_git_port: "22"            # same port as in cluster_git_repository.remote option
argocd_git_host: "github.com"    # same host as in cluster_git_repository.remote option
argocd_namespace: "argocd"       # better to not change


# =====================
#  Traefik Helm Chart
# =====================
traefik_subdomain: "traefik"
traefik_password: "riotkit"
traefik_tls_staging: "true"
traefik_tls_email: "example@example.org"


# allows to override "traefik_defaults" - the dictionary hashes will be merged recursively
traefik_helm_settings: {}

traefik_defaults:
    rbac:
        enabled: true
    additionalArguments:
        - "--certificatesresolvers.default.acme.email={{ traefik_tls_email }}"
        - "--certificatesresolvers.default.acme.storage=/data/acme.json"
        - "--certificatesresolvers.default.acme.tlschallenge=true"
        - "--certificatesresolvers.default.acme.caserver=https://acme-staging-v02.api.letsencrypt.org/directory" # debug

    ingressRoute:
        dashboard:
            enabled: false

    persistence:
        enabled: true
        name: data
        accessMode: ReadWriteOnce
        size: 64Mi
        path: /data

    resources:
       requests:
           cpu: "0"
           memory: "50Mi"
       limits:
          cpu: "1"
          memory: "150Mi"

    providers:
        kubernetesCRD:
            enabled: true
            allowCrossNamespace: true


infracheck_enabled: true
infracheck_domain: "health"
infracheck_max_total_load_average: "2"
infracheck_helm_settings: {}
infracheck_defaults:
    dbVolume:
        storageClassName: local-path
    ingress:
        host: "{{ infracheck_domain }}.{{ main_domain }}"
    settings:
        refresh_time: "600"  # interval between refreshing all checks
        wait_time: "0"       # time in seconds between two checks are running
        check_timeout: "120" # timeout on every check
    checks:
        configuredStr: |
            networking_to_dns.json: |
                {
                    "type": "port-open",
                    "input": {
                        "po_host": "1.1.1.1",
                        "po_port": "53",
                        "po_timeout": "5"
                    }
                }
            max_ram_percentage.json: |
                {
                    "type": "free-ram",
                    "input": {
                        "max_ram_percentage": "85"
                    }
                }
            main_domain_expiration.json: |
                {
                    "type": "domain-expiration",
                    "results_cache_time": "7200",
                    "input": {
                        "domain": "{{ main_domain }}",
                        "alert_days_before": "7"
                    }
                }
            main_domain_tls.json: |
                {
                    "type": "tls",
                    "input": {
                        "domain": "{{ main_domain }}",
                        "alert_days_before": "7"
                    }
                }
            load_average.json: |
                {
                    "type": "load-average-auto",
                    "input": {
                        "maximum_above": "{{ infracheck_max_total_load_average }}",
                        "timing": "15"
                    }
                }
            disk_space.json: |
                {
                    "type": "disk-space",
                    "input": {
                        "dir": "/",
                        "min_req_space": "8"
                    }
                }


# ==============
#  SMTP gateway
# ==============
mail_enabled: true
mail_sending_domain: "{{ main_domain }}"
mail_relay_host: ""
mail_relay_username: ""
mail_relay_password: ""

# ================
#  Sealed Secrets
# ================
secrets_enabled: true
secrets_namespace: "kube-system"

# ====================
#  Telegraf - metrics
# ====================
telegraf_enabled: true
telegraf_agent_interval: "120s"
telegraf_socket_writer_address: "tcp://example.org:8094"
telegraf_certs:
    ca_crt: ...
    tls_crt: ...
    tls_key: ...
